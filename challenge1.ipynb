{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shap\n",
    "DATASET = 'datasets/diamonds/diamonds.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "First let's describe the dataset to find any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are gems with negative price and x,y,z with size 0. First we will clean all inconsistent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(dataset[dataset.price <= 0].index, inplace=True)\n",
    "dataset.drop(dataset[dataset.x <= 0].index, inplace=True)\n",
    "dataset.drop(dataset[dataset.y <= 0].index, inplace=True)\n",
    "dataset.drop(dataset[dataset.z <= 0].index, inplace=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we encode color, cut and clarity to a numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['cut'] = dataset['cut'].map({'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4})\n",
    "dataset['color'] = dataset['color'].map({'J': 0, 'I': 1, 'H': 2, 'G': 3, 'F': 4, 'E': 5, 'D': 6})\n",
    "dataset['clarity'] = dataset['clarity'].map({'I1': 0, 'SI2': 1, 'SI1': 2, 'VS2': 3, 'VS1': 4, 'VVS2': 5, 'VVS1': 6, 'IF': 7})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.boxplot(column='price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a high number of price outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "p = sns.heatmap(dataset.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset's README and a quick Google search says that the most fundamental properties of a diamond are the `carat`, `cut`, `color` and `clarity`, but the correlation matrix shows `cut`, `color` and `clarity` have a _negative_ correlation with `price` and that the properties with the highest correlation to `price` are the `carat` and the `x,y,z` size! My guess is that the `carat` rules the price, even if it has a not so good `cut`, `color` and `clarity`. As the `carat` represents the weight, it is natural that these are bigger volume wise in the `x,y,z` dimensions, so that's why both have a high correlation to price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll do a classic 80/20 train test data split and then run some classic regression models using the `sklearn` library. We'll keep the one with the highest score. As there is a high number of outliers we will use `RobustScaler` for the target which has a high tolerance for outliers, and `StandardScaler` for the other columns.\n",
    "\n",
    "We'll be dropping `depth` as it has a very low correlation with `price`. `x,y,z` will also be dropped due to their high correlation with `carat`. This way the model will be simpler and, therefore, easier to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['price', 'depth', 'x', 'y', 'z'])\n",
    "#X['volume'] = dataset['x'] * dataset['y'] * dataset['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['price']\n",
    "# Split the dataset into train and test sets. Use random_state=42 so that the results are reproducible.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic linear regression\n",
    "model = TransformedTargetRegressor(regressor=LinearRegression(), transformer=RobustScaler()).fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "model = TransformedTargetRegressor(regressor=Lasso(random_state=42), transformer=RobustScaler()).fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM regression\n",
    "model = TransformedTargetRegressor(regressor=SVR(), transformer=RobustScaler()).fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest regression\n",
    "model = TransformedTargetRegressor(regressor=RandomForestRegressor(random_state=42), transformer=RobustScaler()).fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "It seems that the best regression models for this dataset are the ones based on Support Vector Machines and Random Forests. Some cross validations tests can be made to be more sure of which of these two to choose, but both would do a pretty good job with an $R^2$ score of ~0.97. More robust solutions using feature engineering, further data cleaning, using a better decision tree algorithm such as _XGBoost_ and/or neural networks could improve the accuracy even further.\n",
    "\n",
    "## Explainability\n",
    "\n",
    "To explain the Random Forest regression we can check the `feature_importances` as specified here https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "\n",
    "Here we see that features with a high MDI in the forest have a high impact on the final result of the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph feature_importances_ of the model\n",
    "std = np.std([tree.feature_importances_ for tree in model.regressor_.estimators_], axis=0)\n",
    "forest_importances = pd.Series(model.regressor_.feature_importances_, index=X.columns)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `carat` is the clearest `price` indicator. Sadly, there is no easy way of getting this information in a Support Vector Machine model. There is a well known AI explainability library called `SHAP` that can help us in this case and which can be used for other models we may implement.\n",
    "\n",
    "(Takes around 5 minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformedTargetRegressor(regressor=SVR(), transformer=RobustScaler()).fit(X_train, y_train)\n",
    "explainer = shap.KernelExplainer(model.predict, X_train)\n",
    "data = shap.sample(X_test, 100)\n",
    "shap_values = explainer.shap_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the features relevance are quite similar to its `price` correlation on the correlation matrix. These graphs can be shown to Don Francesco to explain both models results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
